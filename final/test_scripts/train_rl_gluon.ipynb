{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a27c97f-f35a-4d84-add7-a62dc9bea6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA RTX A5500 Laptop GPU', major=8, minor=6, total_memory=16383MB, multi_processor_count=58)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c12d022-7fd1-4a04-8592-19987a1b9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# f = h5py.File('../datasets/halfcheetah_medium_expert-v2.hdf5', 'r')\n",
    "# print(f.keys())\n",
    "# print(f['actions'].shape[0])\n",
    "# print(f['infos'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d79e2-ac36-4752-8f0d-4ffd7da898da",
   "metadata": {},
   "source": [
    "Import the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d871880f-ec9a-4dfc-b162-820f5c6bdd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4defe3-2dba-4de9-bd10-a4185aa7390a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Because the actions should be in [-1, +1] range, we do arctanh, model it, then tanh.\n",
    "def data_preprocessor(x):\n",
    "    return np.arctanh(0.995 * np.clip(x, -1.0, +1.0))\n",
    "\n",
    "def data_un_preprocessor(x):\n",
    "    return np.clip(np.tanh(x)/0.995, -1.0, +1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c043cef7-4f4a-4e88-a477-6576b2518ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_str = 1012-185922\n",
      "type of date_str = <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date_str = datetime.strftime(datetime.now(), \"%d%m-%H%M%S\")\n",
    "print(\"date_str =\", date_str)\n",
    "print(\"type of date_str =\", type(date_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4fa6d05-6d87-40ad-ade9-a7a2be51a3de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/hopper-random-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/hopper-medium-replay-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/hopper-medium-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/hopper-medium-expert-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/halfcheetah-random-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/halfcheetah-medium-replay-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/halfcheetah-medium-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/halfcheetah-medium-expert-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/walker2d-random-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/walker2d-medium-replay-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/walker2d-medium-v2/')\n",
      "Fitting TabularPredictor for label: ac0 ...\n",
      "Fitting TabularPredictor for label: ac1 ...\n",
      "Fitting TabularPredictor for label: ac2 ...\n",
      "Fitting TabularPredictor for label: ac3 ...\n",
      "Fitting TabularPredictor for label: ac4 ...\n",
      "Fitting TabularPredictor for label: ac5 ...\n",
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels/walker2d-medium-expert-v2/')\n"
     ]
    }
   ],
   "source": [
    "env_names = ['hopper', 'halfcheetah', 'walker2d']\n",
    "policy_names = ['random', 'medium-replay', 'medium', 'medium-expert']\n",
    "\n",
    "for env_name in env_names:\n",
    "    for policy_name in policy_names:\n",
    "        exp_name = \"{e}-{p}-v2\".format(e=env_name, p=policy_name)\n",
    "        original_train_data = TabularDataset('../datasets/{name}.csv'.format(name=exp_name))\n",
    "        train_data = data_preprocessor(original_train_data)\n",
    "\n",
    "        labels = [x for x in original_train_data.keys() if 'ac' in x]  # which columns to predict based on the others\n",
    "        problem_types = ['regression'] * len(labels)  # type of each prediction problem (optional)\n",
    "        eval_metrics = ['mean_squared_error'] * len(labels)  # metrics used to evaluate predictions for each label (optional)\n",
    "        save_path = 'agModels/{name}'.format(name=exp_name)  # specifies folder to store trained models (optional)\n",
    "\n",
    "        multi_predictor = MultilabelPredictor(labels=labels,\n",
    "                                              problem_types=problem_types,\n",
    "                                              eval_metrics=eval_metrics,\n",
    "                                              path=save_path)\n",
    "        train_hours = 2\n",
    "        train_seconds = int(3600 * train_hours / len(labels))\n",
    "        multi_predictor.fit(train_data, \n",
    "                            time_limit=train_seconds,\n",
    "                            presets=['medium_quality', 'optimize_for_deployment'],\n",
    "                            excluded_model_types=['KNN'],\n",
    "                            verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ae7aad-ccb2-46cd-909a-217cf3787071",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: invalid value encountered in arctanh\n",
      "  result = func(self.values, **kwargs)\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac0\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac1\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac2\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac3\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac4\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-halfcheetah-medium-expert-v2/Predictor_ac5\"\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ac0', 'ac1', 'ac2', 'ac3', 'ac4', 'ac5']\n",
      "['regression', 'regression', 'regression', 'regression', 'regression', 'regression']\n",
      "['mean_squared_error', 'mean_squared_error', 'mean_squared_error', 'mean_squared_error', 'mean_squared_error', 'mean_squared_error']\n",
      "agModels-halfcheetah-medium-expert-v2\n",
      "Fitting TabularPredictor for label: ac0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac0/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 18\n",
      "Label Column: ac0\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23041.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 288.0 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 288.0 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2197.74s of the 3297.43s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.358861\n",
      "[2000]\tvalid_set's l2: 0.332977\n",
      "[3000]\tvalid_set's l2: 0.321029\n",
      "[4000]\tvalid_set's l2: 0.312902\n",
      "[5000]\tvalid_set's l2: 0.307167\n",
      "[6000]\tvalid_set's l2: 0.302794\n",
      "[7000]\tvalid_set's l2: 0.299219\n",
      "[8000]\tvalid_set's l2: 0.296328\n",
      "[9000]\tvalid_set's l2: 0.293859\n",
      "[10000]\tvalid_set's l2: 0.292002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.359291\n",
      "[2000]\tvalid_set's l2: 0.33266\n",
      "[3000]\tvalid_set's l2: 0.319343\n",
      "[4000]\tvalid_set's l2: 0.310872\n",
      "[5000]\tvalid_set's l2: 0.304978\n",
      "[6000]\tvalid_set's l2: 0.300296\n",
      "[7000]\tvalid_set's l2: 0.296927\n",
      "[8000]\tvalid_set's l2: 0.294066\n",
      "[9000]\tvalid_set's l2: 0.291752\n",
      "[10000]\tvalid_set's l2: 0.289735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.361962\n",
      "[2000]\tvalid_set's l2: 0.3344\n",
      "[3000]\tvalid_set's l2: 0.320599\n",
      "[4000]\tvalid_set's l2: 0.311232\n",
      "[5000]\tvalid_set's l2: 0.305322\n",
      "[6000]\tvalid_set's l2: 0.301239\n",
      "[7000]\tvalid_set's l2: 0.297807\n",
      "[8000]\tvalid_set's l2: 0.295152\n",
      "[9000]\tvalid_set's l2: 0.29301\n",
      "[10000]\tvalid_set's l2: 0.29122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.361939\n",
      "[2000]\tvalid_set's l2: 0.335034\n",
      "[3000]\tvalid_set's l2: 0.321741\n",
      "[4000]\tvalid_set's l2: 0.31349\n",
      "[5000]\tvalid_set's l2: 0.307684\n",
      "[6000]\tvalid_set's l2: 0.303396\n",
      "[7000]\tvalid_set's l2: 0.300062\n",
      "[8000]\tvalid_set's l2: 0.297337\n",
      "[9000]\tvalid_set's l2: 0.295017\n",
      "[10000]\tvalid_set's l2: 0.292978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.360369\n",
      "[2000]\tvalid_set's l2: 0.332108\n",
      "[3000]\tvalid_set's l2: 0.319082\n",
      "[4000]\tvalid_set's l2: 0.310907\n",
      "[5000]\tvalid_set's l2: 0.305101\n",
      "[6000]\tvalid_set's l2: 0.300988\n",
      "[7000]\tvalid_set's l2: 0.29764\n",
      "[8000]\tvalid_set's l2: 0.294946\n",
      "[9000]\tvalid_set's l2: 0.292854\n",
      "[10000]\tvalid_set's l2: 0.291053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.358348\n",
      "[2000]\tvalid_set's l2: 0.329696\n",
      "[3000]\tvalid_set's l2: 0.316672\n",
      "[4000]\tvalid_set's l2: 0.308688\n",
      "[5000]\tvalid_set's l2: 0.303207\n",
      "[6000]\tvalid_set's l2: 0.299028\n",
      "[7000]\tvalid_set's l2: 0.295899\n",
      "[8000]\tvalid_set's l2: 0.293222\n",
      "[9000]\tvalid_set's l2: 0.290984\n",
      "[10000]\tvalid_set's l2: 0.289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.362193\n",
      "[2000]\tvalid_set's l2: 0.333067\n",
      "[3000]\tvalid_set's l2: 0.319322\n",
      "[4000]\tvalid_set's l2: 0.31113\n",
      "[5000]\tvalid_set's l2: 0.305441\n",
      "[6000]\tvalid_set's l2: 0.301034\n",
      "[7000]\tvalid_set's l2: 0.297565\n",
      "[8000]\tvalid_set's l2: 0.294636\n",
      "[9000]\tvalid_set's l2: 0.292294\n",
      "[10000]\tvalid_set's l2: 0.290296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.359364\n",
      "[2000]\tvalid_set's l2: 0.331257\n",
      "[3000]\tvalid_set's l2: 0.318678\n",
      "[4000]\tvalid_set's l2: 0.310476\n",
      "[5000]\tvalid_set's l2: 0.304559\n",
      "[6000]\tvalid_set's l2: 0.300331\n",
      "[7000]\tvalid_set's l2: 0.296922\n",
      "[8000]\tvalid_set's l2: 0.294192\n",
      "[9000]\tvalid_set's l2: 0.292013\n",
      "[10000]\tvalid_set's l2: 0.289998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2908\t = Validation score   (-mean_squared_error)\n",
      "\t1398.18s\t = Training   runtime\n",
      "\t126.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 670.83s of the 1770.52s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.341896\n",
      "[2000]\tvalid_set's l2: 0.317923\n",
      "[3000]\tvalid_set's l2: 0.306861\n",
      "[4000]\tvalid_set's l2: 0.299695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4169. Best iteration is:\n",
      "\t[4169]\tvalid_set's l2: 0.298751\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.340348\n",
      "[2000]\tvalid_set's l2: 0.317645\n",
      "[3000]\tvalid_set's l2: 0.30581\n",
      "[4000]\tvalid_set's l2: 0.298726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4172. Best iteration is:\n",
      "\t[4172]\tvalid_set's l2: 0.297743\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.344833\n",
      "[2000]\tvalid_set's l2: 0.320351\n",
      "[3000]\tvalid_set's l2: 0.308796\n",
      "[4000]\tvalid_set's l2: 0.300896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4342. Best iteration is:\n",
      "\t[4341]\tvalid_set's l2: 0.298855\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.343733\n",
      "[2000]\tvalid_set's l2: 0.320788\n",
      "[3000]\tvalid_set's l2: 0.308417\n",
      "[4000]\tvalid_set's l2: 0.300589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4441. Best iteration is:\n",
      "\t[4441]\tvalid_set's l2: 0.298086\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.342616\n",
      "[2000]\tvalid_set's l2: 0.319506\n",
      "[3000]\tvalid_set's l2: 0.307388\n",
      "[4000]\tvalid_set's l2: 0.299906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4694. Best iteration is:\n",
      "\t[4694]\tvalid_set's l2: 0.296507\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.339429\n",
      "[2000]\tvalid_set's l2: 0.31614\n",
      "[3000]\tvalid_set's l2: 0.305432\n",
      "[4000]\tvalid_set's l2: 0.297525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4510. Best iteration is:\n",
      "\t[4510]\tvalid_set's l2: 0.2949\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.342549\n",
      "[2000]\tvalid_set's l2: 0.319603\n",
      "[3000]\tvalid_set's l2: 0.30779\n",
      "[4000]\tvalid_set's l2: 0.300147\n",
      "[5000]\tvalid_set's l2: 0.294996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5214. Best iteration is:\n",
      "\t[5213]\tvalid_set's l2: 0.294084\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.341855\n",
      "[2000]\tvalid_set's l2: 0.318176\n",
      "[3000]\tvalid_set's l2: 0.306355\n",
      "[4000]\tvalid_set's l2: 0.298932\n",
      "[5000]\tvalid_set's l2: 0.293886\n",
      "[6000]\tvalid_set's l2: 0.289867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 6029. Best iteration is:\n",
      "\t[6029]\tvalid_set's l2: 0.289768\n",
      "\t-0.2961\t = Validation score   (-mean_squared_error)\n",
      "\t609.01s\t = Training   runtime\n",
      "\t45.27s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 15.07s of the 1114.76s of remaining time.\n",
      "\tWarning: Model is expected to require 1835.1s to train, which exceeds the maximum time limit of 15.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1089.15s of remaining time.\n",
      "\t-0.2874\t = Validation score   (-mean_squared_error)\n",
      "\t8.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1079.93s of the 1079.78s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 457. Best iteration is:\n",
      "\t[457]\tvalid_set's l2: 0.276298\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 381. Best iteration is:\n",
      "\t[381]\tvalid_set's l2: 0.277294\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 557. Best iteration is:\n",
      "\t[557]\tvalid_set's l2: 0.275046\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 445. Best iteration is:\n",
      "\t[445]\tvalid_set's l2: 0.276923\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 481. Best iteration is:\n",
      "\t[481]\tvalid_set's l2: 0.27522\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 638. Best iteration is:\n",
      "\t[638]\tvalid_set's l2: 0.273145\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 558. Best iteration is:\n",
      "\t[558]\tvalid_set's l2: 0.274803\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 709. Best iteration is:\n",
      "\t[709]\tvalid_set's l2: 0.272542\n",
      "\t-0.2752\t = Validation score   (-mean_squared_error)\n",
      "\t1031.26s\t = Training   runtime\n",
      "\t5.93s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 40.51s of the 40.36s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 12. Best iteration is:\n",
      "\t[12]\tvalid_set's l2: 1.039\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 34.25s of the 34.09s of remaining time.\n",
      "\tWarning: Model is expected to require 2149.7s to train, which exceeds the maximum time limit of 34.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4.38s of the 4.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-12-09 12:12:15,107\tERROR serialization.py:354 -- Failed to unpickle serialized exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 352, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 264, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tSystem error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 352, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 264, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 628, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
      "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 515, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 498, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 466, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/worker.py\", line 2282, in get\n",
      "    raise value\n",
      "ray.exceptions.RaySystemError: System error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 352, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/_private/serialization.py\", line 264, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/home/deadscholar/miniconda3/envs/gluon/lib/python3.9/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -88.74s of remaining time.\n",
      "\t-0.2752\t = Validation score   (-mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3392.18s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "2022-12-09 12:12:18,208\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t174.37s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t75.51s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t17.04s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac0/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac0/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac0/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac0/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac0/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac0/\")\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac1/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 19\n",
      "Label Column: ac1\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21018.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 304.0 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 304.0 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2197.73s of the 3297.42s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 988. Best iteration is:\n",
      "\t[988]\tvalid_set's l2: 0.235682\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 768. Best iteration is:\n",
      "\t[768]\tvalid_set's l2: 0.241849\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.233899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1016. Best iteration is:\n",
      "\t[1016]\tvalid_set's l2: 0.233538\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.235743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1119. Best iteration is:\n",
      "\t[1119]\tvalid_set's l2: 0.233124\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.235318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1124. Best iteration is:\n",
      "\t[1124]\tvalid_set's l2: 0.232648\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.234418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1338. Best iteration is:\n",
      "\t[1338]\tvalid_set's l2: 0.228242\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.234933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1377. Best iteration is:\n",
      "\t[1377]\tvalid_set's l2: 0.228001\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.234152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1749. Best iteration is:\n",
      "\t[1749]\tvalid_set's l2: 0.222894\n",
      "\t-0.232\t = Validation score   (-mean_squared_error)\n",
      "\t2096.54s\t = Training   runtime\n",
      "\t15.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.07s of the 1183.76s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 34. Best iteration is:\n",
      "\t[34]\tvalid_set's l2: 0.432618\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[36]\tvalid_set's l2: 0.419608\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\tvalid_set's l2: 0.416941\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\tvalid_set's l2: 0.417389\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 39. Best iteration is:\n",
      "\t[39]\tvalid_set's l2: 0.405805\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[40]\tvalid_set's l2: 0.398922\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 44. Best iteration is:\n",
      "\t[44]\tvalid_set's l2: 0.383981\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[38]\tvalid_set's l2: 0.408137\n",
      "\t-0.4104\t = Validation score   (-mean_squared_error)\n",
      "\t79.91s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.88s of the 1101.56s of remaining time.\n",
      "\tWarning: Model is expected to require 1918.3s to train, which exceeds the maximum time limit of 1.9s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1074.7s of remaining time.\n",
      "\t-0.232\t = Validation score   (-mean_squared_error)\n",
      "\t8.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1065.85s of the 1065.67s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 455. Best iteration is:\n",
      "\t[455]\tvalid_set's l2: 0.222668\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 388. Best iteration is:\n",
      "\t[388]\tvalid_set's l2: 0.223288\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 397. Best iteration is:\n",
      "\t[397]\tvalid_set's l2: 0.223978\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 403. Best iteration is:\n",
      "\t[403]\tvalid_set's l2: 0.223702\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 577. Best iteration is:\n",
      "\t[577]\tvalid_set's l2: 0.222827\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 605. Best iteration is:\n",
      "\t[605]\tvalid_set's l2: 0.221885\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 662. Best iteration is:\n",
      "\t[662]\tvalid_set's l2: 0.22239\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 622. Best iteration is:\n",
      "\t[622]\tvalid_set's l2: 0.220051\n",
      "\t-0.2226\t = Validation score   (-mean_squared_error)\n",
      "\t1017.32s\t = Training   runtime\n",
      "\t6.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 40.21s of the 40.02s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 11. Best iteration is:\n",
      "\t[11]\tvalid_set's l2: 0.666018\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 33.94s of the 33.75s of remaining time.\n",
      "\tWarning: Model is expected to require 2552.2s to train, which exceeds the maximum time limit of 33.9s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -1.85s of remaining time.\n",
      "\t-0.2226\t = Validation score   (-mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3303.17s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t27.39s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.24s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t18.36s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac1/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac1/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac1/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac1/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac1/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac1/\")\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac2/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 20\n",
      "Label Column: ac2\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20840.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 320.0 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 320.0 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2198.03s of the 3297.86s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.252832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1031. Best iteration is:\n",
      "\t[1031]\tvalid_set's l2: 0.252159\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 981. Best iteration is:\n",
      "\t[981]\tvalid_set's l2: 0.253065\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.254222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1076. Best iteration is:\n",
      "\t[1076]\tvalid_set's l2: 0.252785\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.253816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1098. Best iteration is:\n",
      "\t[1098]\tvalid_set's l2: 0.25189\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.252725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1196. Best iteration is:\n",
      "\t[1196]\tvalid_set's l2: 0.249267\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.250474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1284. Best iteration is:\n",
      "\t[1284]\tvalid_set's l2: 0.2456\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.252439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1402. Best iteration is:\n",
      "\t[1402]\tvalid_set's l2: 0.245925\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.252611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1686. Best iteration is:\n",
      "\t[1686]\tvalid_set's l2: 0.243003\n",
      "\t-0.2492\t = Validation score   (-mean_squared_error)\n",
      "\t2096.12s\t = Training   runtime\n",
      "\t16.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 83.88s of the 1183.72s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\t[26]\tvalid_set's l2: 0.48929\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 34. Best iteration is:\n",
      "\t[34]\tvalid_set's l2: 0.419593\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\t[26]\tvalid_set's l2: 0.492412\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\tvalid_set's l2: 0.403681\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's l2: 0.45772\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's l2: 0.453538\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 37. Best iteration is:\n",
      "\t[37]\tvalid_set's l2: 0.404819\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 33. Best iteration is:\n",
      "\t[33]\tvalid_set's l2: 0.425881\n",
      "\t-0.4434\t = Validation score   (-mean_squared_error)\n",
      "\t79.78s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.71s of the 1101.55s of remaining time.\n",
      "\tWarning: Model is expected to require 2104.1s to train, which exceeds the maximum time limit of 1.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1072.25s of remaining time.\n",
      "\t-0.2492\t = Validation score   (-mean_squared_error)\n",
      "\t8.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1063.5s of the 1063.34s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 368. Best iteration is:\n",
      "\t[368]\tvalid_set's l2: 0.240518\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 505. Best iteration is:\n",
      "\t[505]\tvalid_set's l2: 0.240424\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 548. Best iteration is:\n",
      "\t[548]\tvalid_set's l2: 0.239057\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 583. Best iteration is:\n",
      "\t[583]\tvalid_set's l2: 0.237122\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.235408\n",
      "[2000]\tvalid_set's l2: 0.230721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2571. Best iteration is:\n",
      "\t[2571]\tvalid_set's l2: 0.229005\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.23539\n",
      "[2000]\tvalid_set's l2: 0.230872\n",
      "[3000]\tvalid_set's l2: 0.228196\n",
      "[4000]\tvalid_set's l2: 0.22623\n",
      "[5000]\tvalid_set's l2: 0.224881\n",
      "[6000]\tvalid_set's l2: 0.223698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 6536. Best iteration is:\n",
      "\t[6536]\tvalid_set's l2: 0.223128\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.234536\n",
      "[2000]\tvalid_set's l2: 0.229967\n",
      "[3000]\tvalid_set's l2: 0.227238\n",
      "[4000]\tvalid_set's l2: 0.22536\n",
      "[5000]\tvalid_set's l2: 0.223856\n",
      "[6000]\tvalid_set's l2: 0.222534\n",
      "[7000]\tvalid_set's l2: 0.221489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 7083. Best iteration is:\n",
      "\t[7083]\tvalid_set's l2: 0.221408\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.233947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1335. Best iteration is:\n",
      "\t[1335]\tvalid_set's l2: 0.232006\n",
      "\t-0.2328\t = Validation score   (-mean_squared_error)\n",
      "\t999.42s\t = Training   runtime\n",
      "\t25.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 36.44s of the 36.28s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 16. Best iteration is:\n",
      "\t[16]\tvalid_set's l2: 0.531096\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 30.82s of the 30.66s of remaining time.\n",
      "\tWarning: Model is expected to require 2367.2s to train, which exceeds the maximum time limit of 30.8s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -2.2s of remaining time.\n",
      "\t-0.2328\t = Validation score   (-mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3303.67s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t27.14s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t1.97s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t50.47s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac2/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac2/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac2/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac2/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac2/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac2/\")\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac3/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 21\n",
      "Label Column: ac3\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20848.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 336.0 MB (1.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 21 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 21 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t21 features in original data used to generate 21 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 336.0 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2197.77s of the 3297.47s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.213181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1194. Best iteration is:\n",
      "\t[1194]\tvalid_set's l2: 0.20879\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 999. Best iteration is:\n",
      "\t[999]\tvalid_set's l2: 0.214109\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.214081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1289. Best iteration is:\n",
      "\t[1289]\tvalid_set's l2: 0.207834\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.216146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1358. Best iteration is:\n",
      "\t[1358]\tvalid_set's l2: 0.208354\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.214824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1268. Best iteration is:\n",
      "\t[1268]\tvalid_set's l2: 0.209017\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.214959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1312. Best iteration is:\n",
      "\t[1312]\tvalid_set's l2: 0.208172\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.211944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1114. Best iteration is:\n",
      "\t[1114]\tvalid_set's l2: 0.209238\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.212658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1827. Best iteration is:\n",
      "\t[1827]\tvalid_set's l2: 0.1987\n",
      "\t-0.208\t = Validation score   (-mean_squared_error)\n",
      "\t2096.92s\t = Training   runtime\n",
      "\t15.0s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.44s of the 1184.15s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\tvalid_set's l2: 0.473556\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 42. Best iteration is:\n",
      "\t[42]\tvalid_set's l2: 0.382058\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 39. Best iteration is:\n",
      "\t[39]\tvalid_set's l2: 0.39571\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's l2: 0.46684\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 43. Best iteration is:\n",
      "\t[43]\tvalid_set's l2: 0.379428\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 36. Best iteration is:\n",
      "\t[36]\tvalid_set's l2: 0.41289\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 47. Best iteration is:\n",
      "\t[47]\tvalid_set's l2: 0.363099\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 46. Best iteration is:\n",
      "\t[46]\tvalid_set's l2: 0.365241\n",
      "\t-0.4049\t = Validation score   (-mean_squared_error)\n",
      "\t80.42s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.74s of the 1101.45s of remaining time.\n",
      "\tWarning: Model is expected to require 2071.3s to train, which exceeds the maximum time limit of 1.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1072.65s of remaining time.\n",
      "\t-0.208\t = Validation score   (-mean_squared_error)\n",
      "\t7.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1064.68s of the 1064.5s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 457. Best iteration is:\n",
      "\t[457]\tvalid_set's l2: 0.197661\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 473. Best iteration is:\n",
      "\t[473]\tvalid_set's l2: 0.196767\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 487. Best iteration is:\n",
      "\t[487]\tvalid_set's l2: 0.195757\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 521. Best iteration is:\n",
      "\t[521]\tvalid_set's l2: 0.196187\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 536. Best iteration is:\n",
      "\t[536]\tvalid_set's l2: 0.19777\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 579. Best iteration is:\n",
      "\t[579]\tvalid_set's l2: 0.195737\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 813. Best iteration is:\n",
      "\t[813]\tvalid_set's l2: 0.193305\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 780. Best iteration is:\n",
      "\t[780]\tvalid_set's l2: 0.193829\n",
      "\t-0.1959\t = Validation score   (-mean_squared_error)\n",
      "\t1016.23s\t = Training   runtime\n",
      "\t6.7s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 39.85s of the 39.67s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 10. Best iteration is:\n",
      "\t[10]\tvalid_set's l2: 0.714182\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 33.84s of the 33.65s of remaining time.\n",
      "\tWarning: Model is expected to require 2563.8s to train, which exceeds the maximum time limit of 33.8s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -1.96s of remaining time.\n",
      "\t-0.1959\t = Validation score   (-mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3303.51s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t32.69s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.45s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t19.99s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac3/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac3/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac3/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac3/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac3/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac3/\")\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac4/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 22\n",
      "Label Column: ac4\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20924.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 352.0 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 22 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t22 features in original data used to generate 22 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 352.0 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2197.99s of the 3297.81s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.225402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1039. Best iteration is:\n",
      "\t[1039]\tvalid_set's l2: 0.22441\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.225053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1199. Best iteration is:\n",
      "\t[1199]\tvalid_set's l2: 0.220796\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.22616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1153. Best iteration is:\n",
      "\t[1153]\tvalid_set's l2: 0.22269\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.224333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1204. Best iteration is:\n",
      "\t[1204]\tvalid_set's l2: 0.219781\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.226916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1387. Best iteration is:\n",
      "\t[1387]\tvalid_set's l2: 0.219147\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.224573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1172. Best iteration is:\n",
      "\t[1172]\tvalid_set's l2: 0.220753\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.225066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1322. Best iteration is:\n",
      "\t[1322]\tvalid_set's l2: 0.218228\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.224262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1979. Best iteration is:\n",
      "\t[1979]\tvalid_set's l2: 0.209618\n",
      "\t-0.2194\t = Validation score   (-mean_squared_error)\n",
      "\t2097.01s\t = Training   runtime\n",
      "\t15.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.44s of the 1184.26s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 41. Best iteration is:\n",
      "\t[41]\tvalid_set's l2: 0.387637\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 31. Best iteration is:\n",
      "\t[31]\tvalid_set's l2: 0.44731\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 33. Best iteration is:\n",
      "\t[33]\tvalid_set's l2: 0.434686\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\t[26]\tvalid_set's l2: 0.500609\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 43. Best iteration is:\n",
      "\t[43]\tvalid_set's l2: 0.381673\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 33. Best iteration is:\n",
      "\t[33]\tvalid_set's l2: 0.43238\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 49. Best iteration is:\n",
      "\t[49]\tvalid_set's l2: 0.359654\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[40]\tvalid_set's l2: 0.390051\n",
      "\t-0.4168\t = Validation score   (-mean_squared_error)\n",
      "\t80.53s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.65s of the 1101.47s of remaining time.\n",
      "\tWarning: Model is expected to require 2114.1s to train, which exceeds the maximum time limit of 1.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1072.13s of remaining time.\n",
      "\t-0.2194\t = Validation score   (-mean_squared_error)\n",
      "\t8.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1063.85s of the 1063.69s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 431. Best iteration is:\n",
      "\t[431]\tvalid_set's l2: 0.208147\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 450. Best iteration is:\n",
      "\t[450]\tvalid_set's l2: 0.209503\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 472. Best iteration is:\n",
      "\t[472]\tvalid_set's l2: 0.208927\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 617. Best iteration is:\n",
      "\t[617]\tvalid_set's l2: 0.206456\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 508. Best iteration is:\n",
      "\t[508]\tvalid_set's l2: 0.209676\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 706. Best iteration is:\n",
      "\t[706]\tvalid_set's l2: 0.206596\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 557. Best iteration is:\n",
      "\t[557]\tvalid_set's l2: 0.208326\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 721. Best iteration is:\n",
      "\t[721]\tvalid_set's l2: 0.204342\n",
      "\t-0.2077\t = Validation score   (-mean_squared_error)\n",
      "\t1015.79s\t = Training   runtime\n",
      "\t5.96s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 40.27s of the 40.11s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 15. Best iteration is:\n",
      "\t[15]\tvalid_set's l2: 0.523617\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 34.24s of the 34.08s of remaining time.\n",
      "\tWarning: Model is expected to require 2776.6s to train, which exceeds the maximum time limit of 34.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -4.45s of remaining time.\n",
      "\t-0.2077\t = Validation score   (-mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3306.16s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t33.68s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.64s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t18.93s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac4/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac4/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac4/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac4/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac4/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac4/\")\n",
      "Presets specified: ['high_quality', 'optimize_for_deployment']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3300s\n",
      "AutoGluon will save models to \"agModels-halfcheetah-medium-expert-v2/Predictor_ac5/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 2 19:50:29 UTC 2022\n",
      "Train Data Rows:    2000000\n",
      "Train Data Columns: 23\n",
      "Label Column: ac5\n",
      "Preprocessing data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: ac5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20731.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 368.0 MB (1.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 23 | ['ob0', 'ob1', 'ob2', 'ob3', 'ob4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t23 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 368.0 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2197.95s of the 3297.74s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.248063\n",
      "[2000]\tvalid_set's l2: 0.232471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2759. Best iteration is:\n",
      "\t[2759]\tvalid_set's l2: 0.2266\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 827. Best iteration is:\n",
      "\t[827]\tvalid_set's l2: 0.255477\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 845. Best iteration is:\n",
      "\t[845]\tvalid_set's l2: 0.250438\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.246891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1179. Best iteration is:\n",
      "\t[1179]\tvalid_set's l2: 0.242791\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.248243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1267. Best iteration is:\n",
      "\t[1267]\tvalid_set's l2: 0.242505\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.246917\n",
      "[2000]\tvalid_set's l2: 0.231276\n",
      "[3000]\tvalid_set's l2: 0.224454\n",
      "[4000]\tvalid_set's l2: 0.220184\n",
      "[5000]\tvalid_set's l2: 0.217109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5080. Best iteration is:\n",
      "\t[5080]\tvalid_set's l2: 0.216924\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.245847\n",
      "[2000]\tvalid_set's l2: 0.230781\n",
      "[3000]\tvalid_set's l2: 0.223889\n",
      "[4000]\tvalid_set's l2: 0.219569\n",
      "[5000]\tvalid_set's l2: 0.216625\n",
      "[6000]\tvalid_set's l2: 0.214362\n",
      "[7000]\tvalid_set's l2: 0.212542\n",
      "[8000]\tvalid_set's l2: 0.211112\n",
      "[9000]\tvalid_set's l2: 0.209895\n",
      "[10000]\tvalid_set's l2: 0.20884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.247369\n",
      "[2000]\tvalid_set's l2: 0.232048\n",
      "[3000]\tvalid_set's l2: 0.224907\n",
      "[4000]\tvalid_set's l2: 0.22064\n",
      "[5000]\tvalid_set's l2: 0.217486\n",
      "[6000]\tvalid_set's l2: 0.215209\n",
      "[7000]\tvalid_set's l2: 0.213405\n",
      "[8000]\tvalid_set's l2: 0.211908\n",
      "[9000]\tvalid_set's l2: 0.210624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 9368. Best iteration is:\n",
      "\t[9368]\tvalid_set's l2: 0.210203\n",
      "\t-0.2317\t = Validation score   (-mean_squared_error)\n",
      "\t2068.76s\t = Training   runtime\n",
      "\t47.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 80.27s of the 1180.07s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\tvalid_set's l2: 0.465047\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\tvalid_set's l2: 0.465586\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\t[26]\tvalid_set's l2: 0.478359\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\tvalid_set's l2: 0.460699\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[21]\tvalid_set's l2: 0.530273\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 22. Best iteration is:\n",
      "\t[22]\tvalid_set's l2: 0.516847\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[29]\tvalid_set's l2: 0.453671\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\tvalid_set's l2: 0.418947\n",
      "\t-0.4737\t = Validation score   (-mean_squared_error)\n",
      "\t76.36s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1.3s of the 1101.09s of remaining time.\n",
      "\tWarning: Model is expected to require 2764.4s to train, which exceeds the maximum time limit of 1.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1062.7s of remaining time.\n",
      "\t-0.2317\t = Validation score   (-mean_squared_error)\n",
      "\t10.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['KNN']\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1051.57s of the 1051.37s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 442. Best iteration is:\n",
      "\t[442]\tvalid_set's l2: 0.224129\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 336. Best iteration is:\n",
      "\t[336]\tvalid_set's l2: 0.22478\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.221245\n",
      "[2000]\tvalid_set's l2: 0.217817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2265. Best iteration is:\n",
      "\t[2264]\tvalid_set's l2: 0.217123\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.220251\n",
      "[2000]\tvalid_set's l2: 0.216754\n",
      "[3000]\tvalid_set's l2: 0.214504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3980. Best iteration is:\n",
      "\t[3980]\tvalid_set's l2: 0.212875\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.220161\n",
      "[2000]\tvalid_set's l2: 0.216742\n",
      "[3000]\tvalid_set's l2: 0.214487\n",
      "[4000]\tvalid_set's l2: 0.212752\n",
      "[5000]\tvalid_set's l2: 0.211382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5362. Best iteration is:\n",
      "\t[5362]\tvalid_set's l2: 0.210932\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.220719\n",
      "[2000]\tvalid_set's l2: 0.21725\n",
      "[3000]\tvalid_set's l2: 0.215125\n",
      "[4000]\tvalid_set's l2: 0.213464\n",
      "[5000]\tvalid_set's l2: 0.212096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5565. Best iteration is:\n",
      "\t[5564]\tvalid_set's l2: 0.211396\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.220897\n",
      "[2000]\tvalid_set's l2: 0.217533\n",
      "[3000]\tvalid_set's l2: 0.215309\n",
      "[4000]\tvalid_set's l2: 0.213515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4409. Best iteration is:\n",
      "\t[4409]\tvalid_set's l2: 0.212931\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 0.221273\n",
      "[2000]\tvalid_set's l2: 0.217819\n",
      "[3000]\tvalid_set's l2: 0.215504\n",
      "[4000]\tvalid_set's l2: 0.21376\n",
      "[5000]\tvalid_set's l2: 0.212362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5612. Best iteration is:\n",
      "\t[5612]\tvalid_set's l2: 0.211637\n",
      "\t-0.2157\t = Validation score   (-mean_squared_error)\n",
      "\t982.17s\t = Training   runtime\n",
      "\t37.64s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 29.46s of the 29.26s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 25. Best iteration is:\n",
      "\t[25]\tvalid_set's l2: 0.307398\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 24.45s of the 24.25s of remaining time.\n",
      "\tWarning: Model is expected to require 2988.8s to train, which exceeds the maximum time limit of 24.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -17.23s of remaining time.\n",
      "\t-0.2157\t = Validation score   (-mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3318.86s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t89.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.35s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t81.87s\t = Training   runtime\n",
      "Deleting model LightGBMXT_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac5/models/LightGBMXT_BAG_L1/ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac5/models/LightGBM_BAG_L1/ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac5/models/WeightedEnsemble_L2/ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac5/models/LightGBMXT_BAG_L2/ will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under agModels-halfcheetah-medium-expert-v2/Predictor_ac5/models/WeightedEnsemble_L3/ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-halfcheetah-medium-expert-v2/Predictor_ac5/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('agModels-halfcheetah-medium-expert-v2/')\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"halfcheetah-medium-expert-v2\"\n",
    "original_train_data = TabularDataset('../datasets/{name}.csv'.format(name=exp_name))\n",
    "# train_data = data_preprocessor(original_train_data).sample(n=100000, random_state=0)\n",
    "train_data = data_preprocessor(original_train_data)\n",
    "\n",
    "labels = [x for x in original_train_data.keys() if 'ac' in x]  # which columns to predict based on the others\n",
    "problem_types = ['regression'] * len(labels)  # type of each prediction problem (optional)\n",
    "eval_metrics = ['mean_squared_error'] * len(labels)  # metrics used to evaluate predictions for each label (optional)\n",
    "save_path = 'agModels-{name}'.format(name=exp_name)  # specifies folder to store trained models (optional)\n",
    "\n",
    "print(labels)\n",
    "print(problem_types)\n",
    "print(eval_metrics)\n",
    "print(save_path)\n",
    "\n",
    "excluded_model_types = ['KNN']\n",
    "\n",
    "multi_predictor = MultilabelPredictor(labels=labels,\n",
    "                                      problem_types=problem_types,\n",
    "                                      eval_metrics=eval_metrics,\n",
    "                                      path=save_path)\n",
    "train_hours = 5.5\n",
    "train_seconds = int(3600 * train_hours / len(labels))\n",
    "multi_predictor.fit(train_data, \n",
    "                   time_limit=train_seconds,\n",
    "                    presets=['high_quality', 'optimize_for_deployment'],\n",
    "                    excluded_model_types=['KNN'],\n",
    "                    num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adad5fc-021b-4c8a-b67c-9311351c1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultilabelPredictor at 0x7f59de62b550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultilabelPredictor.load('agModels/halfcheetah-medium-expert-v2_high-quality_01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e31b5-3199-46d5-b046-c06159599d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon]",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

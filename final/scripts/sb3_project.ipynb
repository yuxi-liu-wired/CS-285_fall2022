{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f7f23a-bc56-4611-aac9-fdf62590389c",
   "metadata": {},
   "source": [
    "## Part 0: Install packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26b5dbf-033c-43e5-9151-bdb71f7d5ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myuxiliu1995\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\DeadScholar\\Programming\\CS 285 Fall 2022\\CS-285_fall2022\\final\\scripts\\wandb\\run-20221022_190509-15zqjuf8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yuxiliu1995/sb3-test/runs/15zqjuf8\" target=\"_blank\">super-bird-6</a></strong> to <a href=\"https://wandb.ai/yuxiliu1995/sb3-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yuxiliu1995/sb3-test/runs/15zqjuf8?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x258bf492d10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME=\"SB3 funbling\"\n",
    "WANDB_NOTEBOOK_NAME = \"SB3 test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9b68f3-8d13-4540-bd89-496ea488e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ipdb\n",
    "%pdb on\n",
    "from stable_baselines3 import SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cd5272-7990-46eb-9546-451518d3e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">super-bird-6</strong>: <a href=\"https://wandb.ai/yuxiliu1995/sb3-test/runs/15zqjuf8\" target=\"_blank\">https://wandb.ai/yuxiliu1995/sb3-test/runs/15zqjuf8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_190509-15zqjuf8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"sb3-test\")\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "model = SAC(\"MlpPolicy\", env).learn(total_timesteps=10000)\n",
    "# Save the model\n",
    "model.save(\"sac_pendulum\")\n",
    "# Load the trained model\n",
    "model = SAC.load(\"sac_pendulum\")\n",
    "# Start a new episode\n",
    "obs = env.reset()\n",
    "# What action to take in state `obs`?\n",
    "action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(model.policy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a227fa5-c675-45e9-a017-8c6675e688b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stable_baselines3.sac.policies.SACPolicy"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efb75f54-c187-4ef5-88c5-411f58037371",
   "metadata": {},
   "source": [
    "## Part 1: Getting environments\n",
    "\n",
    "We need 4 kinds of environments to try out on: a discrete one and a continuous one; a simple one and a complex one.\n",
    "\n",
    "|            | simple                      | complex                |\n",
    "|------------|-----------------------------|------------------------|\n",
    "| discrete   | toy text, minigrid          | minigrid, crafter      |\n",
    "| continuous | mountain car cont | half cheetah, humanoid |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe0b5a8-b486-4e8b-bee3-08650a2682bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete, simple: toy text environments from OpenAI Gym itself.\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=True)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afd601-6b75-4c83-9e41-6d9c323c9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete, both: minigrid\n",
    "\n",
    "# ?? https://github.com/Farama-Foundation/MiniGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb25c93-d624-468c-bbc5-61298ef37d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# discrete, complex: crafter\n",
    "# https://github.com/danijar/crafter\n",
    "\n",
    "import crafter\n",
    "\n",
    "env = gym.make('CrafterReward-v1')  # Or CrafterNoReward-v1\n",
    "env = crafter.Recorder(\n",
    "  env, './data/crafter',\n",
    "  save_stats=True,\n",
    "  save_video=False,\n",
    "  save_episode=False,\n",
    ")\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "  action = env.action_space.sample()\n",
    "  obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87841184-751f-48f4-9d55-14c5abc341c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous, simple: mountain car\n",
    "\n",
    "# continuous, complex: half cheetah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08777c4-1e9d-4ffc-96dd-4114d3a4ac0b",
   "metadata": {},
   "source": [
    "## Part 2: Getting baseline training algorithms\n",
    "\n",
    "We consider the following baselines:\n",
    "* deep Q network, as baseline for discrete environments...?\n",
    "* model-free SAC, as the baseline for continuous environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3c33f-0f96-438e-a48c-4e58af4d696c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\rich\\live.py:229: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\rich\\live.py:229: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90.2     |\n",
      "|    ep_rew_mean     | -178     |\n",
      "| time/              |          |\n",
      "|    fps             | 610      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.8         |\n",
      "|    ep_rew_mean          | -195         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043952307 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000767    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 620          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 91.7       |\n",
      "|    ep_rew_mean          | -177       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842151 |\n",
      "|    clip_fraction        | 0.044      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.00504    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 702        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00685   |\n",
      "|    value_loss           | 1.51e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.8        |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 449         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979502 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.00282    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 682         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.8        |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 428         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010677635 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.00207    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 717         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.3        |\n",
      "|    ep_rew_mean          | -152        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009728635 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.000967   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 513         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 101        |\n",
      "|    ep_rew_mean          | -136       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 423        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00872628 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | -0.00448   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 239        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00803   |\n",
      "|    value_loss           | 659        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011386683 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.00137     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 288         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018671619 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.186      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    value_loss           | 487         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 117          |\n",
      "|    ep_rew_mean          | -142         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 426          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046278927 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -0.000118    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 344          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 753          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 121         |\n",
      "|    ep_rew_mean          | -144        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 429         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010120368 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.000256   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | -133        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007461289 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.00677    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 129          |\n",
      "|    ep_rew_mean          | -121         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 435          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065678097 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -0.000456    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 413          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | -120        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008686492 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.00018     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 140          |\n",
      "|    ep_rew_mean          | -124         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 437          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090387855 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -4.67e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00937     |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006117998 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.000609   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    value_loss           | 567         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 149          |\n",
      "|    ep_rew_mean          | -103         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 435          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068832813 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | -5.15e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 534          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 159          |\n",
      "|    ep_rew_mean          | -90.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 437          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050773313 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.000113     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 378          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | -82.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 436         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007011761 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 559         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 187          |\n",
      "|    ep_rew_mean          | -76.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031155685 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 194         |\n",
      "|    ep_rew_mean          | -73         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009995822 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 204          |\n",
      "|    ep_rew_mean          | -70.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 438          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018563865 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 213          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 303          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | -72         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012198858 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# PPO\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Instantiate the agent\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "# Train the agent and display a progress bar\n",
    "model.learn(total_timesteps=int(2e5), progress_bar=True)\n",
    "# Save the agent\n",
    "model.save(\"ppo_lunar\")\n",
    "\n",
    "# load agent\n",
    "del model\n",
    "# NOTE: if you have loading issue, you can pass `print_system_info=True`\n",
    "# to compare the system on which the model was trained vs the current one\n",
    "# model = DQN.load(\"dqn_lunar\", env=env, print_system_info=True)\n",
    "model = DQN.load(\"ppo_lunar\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "# NOTE: If you use wrappers with your environment that modify rewards,\n",
    "#       this will be reflected here. To evaluate with original rewards,\n",
    "#       wrap environment in a \"Monitor\" wrapper before other wrappers.\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    # env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34064142-ee7e-4efc-8d39-a3fd26a9192a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 15       |\n",
      "|    ep_rew_mean        | 15       |\n",
      "| time/                 |          |\n",
      "|    fps                | 403      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 0.221    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 16.5     |\n",
      "|    ep_rew_mean        | 16.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 416      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.69    |\n",
      "|    explained_variance | -0.00388 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.68     |\n",
      "|    value_loss         | 7.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 17.1     |\n",
      "|    ep_rew_mean        | 17.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 419      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.692   |\n",
      "|    explained_variance | 0.00115  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    value_loss         | 6.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 18.6     |\n",
      "|    ep_rew_mean        | 18.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 422      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.674   |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    value_loss         | 5.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 21.2     |\n",
      "|    ep_rew_mean        | 21.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 426      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.685   |\n",
      "|    explained_variance | -0.00424 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -5.04    |\n",
      "|    value_loss         | 235      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 24.7     |\n",
      "|    ep_rew_mean        | 24.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 426      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.632   |\n",
      "|    explained_variance | 0.00577  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -2.61    |\n",
      "|    value_loss         | 311      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 27.4      |\n",
      "|    ep_rew_mean        | 27.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 425       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.687    |\n",
      "|    explained_variance | -0.000764 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 30.1     |\n",
      "|    ep_rew_mean        | 30.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.593   |\n",
      "|    explained_variance | 0.0274   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.9     |\n",
      "|    ep_rew_mean        | 32.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.664   |\n",
      "|    explained_variance | 0.00125  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    value_loss         | 3.82     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 35.9      |\n",
      "|    ep_rew_mean        | 35.9      |\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.684    |\n",
      "|    explained_variance | -0.000148 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.952     |\n",
      "|    value_loss         | 3.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 37.9      |\n",
      "|    ep_rew_mean        | 37.9      |\n",
      "| time/                 |           |\n",
      "|    fps                | 435       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.682    |\n",
      "|    explained_variance | -0.000163 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.915     |\n",
      "|    value_loss         | 3         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 38.8      |\n",
      "|    ep_rew_mean        | 38.8      |\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.623    |\n",
      "|    explained_variance | -9.66e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.96      |\n",
      "|    value_loss         | 2.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 40.7      |\n",
      "|    ep_rew_mean        | 40.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 440       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.613    |\n",
      "|    explained_variance | -3.65e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -14.8     |\n",
      "|    value_loss         | 1.6e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 42.5     |\n",
      "|    ep_rew_mean        | 42.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 443      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.41    |\n",
      "|    explained_variance | 0.000346 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 1.02     |\n",
      "|    value_loss         | 1.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 43.1      |\n",
      "|    ep_rew_mean        | 43.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.532    |\n",
      "|    explained_variance | -0.000303 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.73      |\n",
      "|    value_loss         | 1.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 44.3     |\n",
      "|    ep_rew_mean        | 44.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.614   |\n",
      "|    explained_variance | 0.000102 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.397    |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.3     |\n",
      "|    ep_rew_mean        | 47.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 450      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.602   |\n",
      "|    explained_variance | 7.75e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.382    |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 49.9      |\n",
      "|    ep_rew_mean        | 49.9      |\n",
      "| time/                 |           |\n",
      "|    fps                | 452       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.381    |\n",
      "|    explained_variance | -4.59e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.914     |\n",
      "|    value_loss         | 0.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 52.2     |\n",
      "|    ep_rew_mean        | 52.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 455      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.627   |\n",
      "|    explained_variance | 2.74e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -6.16    |\n",
      "|    value_loss         | 1.15e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54.1     |\n",
      "|    ep_rew_mean        | 54.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 457      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.628   |\n",
      "|    explained_variance | 1.65e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    value_loss         | 0.382    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:406: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "# advantage actor-critic\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)\n",
    "        \n",
    "images = []\n",
    "obs = model.env.reset()\n",
    "img = model.env.render(mode=\"rgb_array\")\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _ ,_ = model.env.step(action)\n",
    "    img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "imageio.mimsave(\"cartpole_a2c.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fdab57-146d-40dd-8c5a-43a80da9cdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\DeadScholar\\Programming\\CS 285 Fall 2022\\CS-285_fall2022\\final\\scripts\\wandb\\run-20221022_195516-1aiv34j0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yuxiliu1995/sb3-test/runs/1aiv34j0\" target=\"_blank\">rural-totem-9</a></strong> to <a href=\"https://wandb.ai/yuxiliu1995/sb3-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rural-totem-9</strong>: <a href=\"https://wandb.ai/yuxiliu1995/sb3-test/runs/1aiv34j0\" target=\"_blank\">https://wandb.ai/yuxiliu1995/sb3-test/runs/1aiv34j0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221022_195516-1aiv34j0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.sac.policies.SACPolicy'>\n"
     ]
    }
   ],
   "source": [
    "# SAC \n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "wandb.init(project=\"sb3-test\")\n",
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "model = SAC(\"MlpPolicy\", env).learn(total_timesteps=40000)\n",
    "# Save the model\n",
    "model.save(\"sac_mtcar_cont\")\n",
    "# Load the trained model\n",
    "model = SAC.load(\"sac_mtcar_cont\")\n",
    "# Start a new episode\n",
    "obs = env.reset()\n",
    "# What action to take in state `obs`?\n",
    "action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(model.policy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2706bb8-a35a-47fc-9603-8122878976bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Viewer.__del__ at 0x000002590CC1C550>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 185, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 101, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 332, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 858, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"C:\\Users\\DeadScholar\\miniconda3\\envs\\sb3\\lib\\_weakrefset.py\", line 114, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x0000025979197E20; to 'Win32Window' at 0x000002595156D5A0>\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "model = SAC.load(\"sac_mtcar_cont\")\n",
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "obs = env.reset()\n",
    "img = env.render(mode=\"rgb_array\")\n",
    "for i in range(350):\n",
    "    images.append(img)\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _ ,_ = env.step(action)\n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "\n",
    "imageio.mimsave(\"sac_mtcar_cont.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f9d0e-58be-4a73-a27c-595dbf207c06",
   "metadata": {},
   "source": [
    "## Part 3: Getting Dreamer working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd656aa-12c9-42eb-9a31-bc6786ba5473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9516229-0f7d-4348-9ba6-43321ed232e6",
   "metadata": {},
   "source": [
    "## Part 4: Getting something else working\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd52c7d-257d-4745-808e-6ee801196e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae99e1-8399-430d-9fe2-70643bc73d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d1bff-7394-4da4-9eaf-e3d83e354353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rllib]",
   "language": "python",
   "name": "conda-env-rllib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

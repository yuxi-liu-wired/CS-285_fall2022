{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is my modified version of `run_hw2.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DeadScholar\\Programming\\CS 285 Fall 2022\\CS-285_fall2022\\hw1\n"
          ]
        }
      ],
      "source": [
        "%cd C:\\Users\\DeadScholar\\Programming\\CS 285 Fall 2022\\CS-285_fall2022\\hw2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title test GPU availability\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qUmV93fif6S"
      },
      "source": [
        "## Run Policy Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lN-gZkqiijnR"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from cs285.infrastructure.rl_trainer import RL_Trainer\n",
        "from cs285.agents.pg_agent import PGAgent\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6NaOWhOinnU"
      },
      "outputs": [],
      "source": [
        "#@title runtime arguments\n",
        "\n",
        "class Args:\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "    return getattr(self, key)\n",
        "\n",
        "  def __setitem__(self, key, val):\n",
        "    setattr(self, key, val)\n",
        "\n",
        "  def __contains__(self, key):\n",
        "    return hasattr(self, key)\n",
        "\n",
        "  env_name = 'CartPole-v0' #@param\n",
        "  exp_name = 'q1_sb_rtg_na' #@param\n",
        "\n",
        "  #@markdown main parameters of interest\n",
        "  n_iter = 100 #@param {type: \"integer\"}\n",
        "\n",
        "  ## PDF will tell you how to set ep_len\n",
        "  ## and discount for each environment\n",
        "  ep_len = 200 #@param {type: \"integer\"}\n",
        "  discount = 0.95 #@param {type: \"number\"}\n",
        "\n",
        "  reward_to_go = True #@param {type: \"boolean\"}\n",
        "  nn_baseline = False #@param {type: \"boolean\"}\n",
        "  gae_lambda = None #@param {type: \"float\"}\n",
        "  dont_standardize_advantages = False #@param {type: \"boolean\"}\n",
        "\n",
        "  #@markdown batches and steps\n",
        "  batch_size = 1000 #@param {type: \"integer\"}\n",
        "  eval_batch_size = 400 #@param {type: \"integer\"}\n",
        "\n",
        "  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n",
        "  learning_rate =  5e-3 #@param {type: \"number\"}\n",
        "\n",
        "  #@markdown MLP parameters\n",
        "  n_layers = 2 #@param {type: \"integer\"}\n",
        "  size = 64 #@param {type: \"integer\"}\n",
        "\n",
        "  #@markdown system\n",
        "  save_params = False #@param {type: \"boolean\"}\n",
        "  no_gpu = False #@param {type: \"boolean\"}\n",
        "  which_gpu = 0 #@param {type: \"integer\"}\n",
        "  seed = 1 #@param {type: \"integer\"}\n",
        "    \n",
        "  action_noise_std = 0 #@param {type: \"float\"}\n",
        "\n",
        "  #@markdown logging\n",
        "  ## default is to not log video so\n",
        "  ## that logs are small enough to be\n",
        "  ## uploaded to gradscope\n",
        "  video_log_freq =  -1#@param {type: \"integer\"}\n",
        "  scalar_log_freq =  1#@param {type: \"integer\"}\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "## ensure compatibility with hw1 code\n",
        "args['train_batch_size'] = args['batch_size']\n",
        "\n",
        "if args['video_log_freq'] > 0:\n",
        "  import warnings\n",
        "  warnings.warn(\n",
        "      '''\\nLogging videos will make eventfiles too'''\n",
        "      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n",
        "      '''\\nfor the runs you intend to submit.''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eScWwHhnsYkd"
      },
      "outputs": [],
      "source": [
        "#@title create directory for logging\n",
        "\n",
        "data_path = '''/content/cs285_f2022/''' \\\n",
        "            '''homework_fall2022/hw2/data'''\n",
        "\n",
        "if not (os.path.exists(data_path)):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "logdir = os.path.join(data_path, logdir)\n",
        "args['logdir'] = logdir\n",
        "if not(os.path.exists(logdir)):\n",
        "    os.makedirs(logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aljzrLdAsvNu"
      },
      "outputs": [],
      "source": [
        "## define policy gradient trainer\n",
        "\n",
        "class PG_Trainer(object):\n",
        "\n",
        "    def __init__(self, params):\n",
        "\n",
        "        #####################\n",
        "        ## SET AGENT PARAMS\n",
        "        #####################\n",
        "\n",
        "        computation_graph_args = {\n",
        "            'n_layers': params['n_layers'],\n",
        "            'size': params['size'],\n",
        "            'learning_rate': params['learning_rate'],\n",
        "            }\n",
        "\n",
        "        estimate_advantage_args = {\n",
        "            'gamma': params['discount'],\n",
        "            'standardize_advantages': not(params['dont_standardize_advantages']),\n",
        "            'reward_to_go': params['reward_to_go'],\n",
        "            'nn_baseline': params['nn_baseline'],\n",
        "            'gae_lambda': params['gae_lambda'],\n",
        "        }\n",
        "\n",
        "        train_args = {\n",
        "            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n",
        "        }\n",
        "\n",
        "        agent_params = {**computation_graph_args, **estimate_advantage_args, **train_args}\n",
        "\n",
        "        self.params = params\n",
        "        self.params['agent_class'] = PGAgent\n",
        "        self.params['agent_params'] = agent_params\n",
        "        self.params['batch_size_initial'] = self.params['batch_size']\n",
        "\n",
        "        ################\n",
        "        ## RL TRAINER\n",
        "        ################\n",
        "\n",
        "        self.rl_trainer = RL_Trainer(self.params)\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        self.rl_trainer.run_training_loop(\n",
        "            self.params['n_iter'],\n",
        "            collect_policy = self.rl_trainer.agent.actor,\n",
        "            eval_policy = self.rl_trainer.agent.actor,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2rCuQsRsd3N"
      },
      "outputs": [],
      "source": [
        "## run training\n",
        "\n",
        "print(args.logdir)\n",
        "trainer = PG_Trainer(args)\n",
        "trainer.run_training_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km7LlYvhqKTl"
      },
      "outputs": [],
      "source": [
        "#@markdown You can visualize your runs with tensorboard from within the notebook\n",
        "\n",
        "## requires tensorflow==2.3.0\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/cs285_f2022/homework_fall2022/hw2/data"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
